{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: Understanding Regression Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: Calculate MAE and MSE on test predictions and compare errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.2429\n",
      "Mean Squared Error (MSE): 0.0590\n",
      "MSE is smaller or equal to MAE, which is unusual as MSE penalizes larger errors more.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Sample data (replace with your dataset)\n",
    "X = np.array([[1], [2], [3], [4], [5]])\n",
    "y = np.array([1.2, 1.9, 3.2, 3.8, 5.1])\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a simple linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate MAE and MSE\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "\n",
    "# Comparison note\n",
    "if mae < mse:\n",
    "    print(\"MAE is smaller than MSE, indicating lower average absolute errors.\")\n",
    "else:\n",
    "    print(\"MSE is smaller or equal to MAE, which is unusual as MSE penalizes larger errors more.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Evaluate R2 Score on varying datasets and discuss significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score on linear data with low noise: 0.9958\n",
      "R2 score on linear data with high noise: 0.9420\n",
      "R2 score on non-linear quadratic data: -0.0800\n",
      "\n",
      "Significance of R2 score:\n",
      "- R2 score measures how well the model explains variance in the data.\n",
      "- Values closer to 1 indicate better fit; values near 0 or negative mean poor fit.\n",
      "- High noise lowers R2, showing the model explains less variance.\n",
      "- For non-linear data, a linear model yields lower R2, highlighting model choice importance.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Function to train and evaluate model on a dataset\n",
    "def evaluate_r2(X, y, description):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    print(f\"R2 score on {description}: {r2:.4f}\")\n",
    "    return r2\n",
    "\n",
    "# Dataset 1: Simple linear relation with low noise\n",
    "X1, y1 = make_regression(n_samples=100, n_features=1, noise=5, random_state=1)\n",
    "r2_1 = evaluate_r2(X1, y1, \"linear data with low noise\")\n",
    "\n",
    "# Dataset 2: Linear relation with higher noise\n",
    "X2, y2 = make_regression(n_samples=100, n_features=1, noise=20, random_state=1)\n",
    "r2_2 = evaluate_r2(X2, y2, \"linear data with high noise\")\n",
    "\n",
    "# Dataset 3: Non-linear relation (quadratic)\n",
    "X3 = np.linspace(-3, 3, 100).reshape(-1, 1)\n",
    "y3 = 2*X3.flatten()**2 + 3 + np.random.normal(0, 3, 100)\n",
    "r2_3 = evaluate_r2(X3, y3, \"non-linear quadratic data\")\n",
    "\n",
    "# Discussion:\n",
    "print(\"\\nSignificance of R2 score:\")\n",
    "print(\"- R2 score measures how well the model explains variance in the data.\")\n",
    "print(\"- Values closer to 1 indicate better fit; values near 0 or negative mean poor fit.\")\n",
    "print(\"- High noise lowers R2, showing the model explains less variance.\")\n",
    "print(\"- For non-linear data, a linear model yields lower R2, highlighting model choice importance.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: Use a sample dataset, compute all three metrics, and deduce model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 12.03\n",
      "Mean Squared Error (MSE): 246.12\n",
      "R² Score: 0.9681\n",
      "\n",
      "Model Performance Interpretation:\n",
      "- MAE provides the average magnitude of errors in the predictions, in the same units as the output.\n",
      "- MSE penalizes larger errors more due to squaring, making it sensitive to outliers.\n",
      "- R² score indicates the proportion of variance explained by the model (closer to 1 is better).\n",
      "The model fits the data very well.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Generate a sample regression dataset\n",
    "X, y = make_regression(n_samples=200, n_features=1, noise=15, random_state=42)\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print results\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "# Deduce model performance\n",
    "print(\"\\nModel Performance Interpretation:\")\n",
    "print(\"- MAE provides the average magnitude of errors in the predictions, in the same units as the output.\")\n",
    "print(\"- MSE penalizes larger errors more due to squaring, making it sensitive to outliers.\")\n",
    "print(\"- R² score indicates the proportion of variance explained by the model (closer to 1 is better).\")\n",
    "\n",
    "if r2 > 0.8:\n",
    "    print(\"The model fits the data very well.\")\n",
    "elif r2 > 0.5:\n",
    "    print(\"The model has a moderate fit; there might be room for improvement.\")\n",
    "else:\n",
    "    print(\"The model does not fit the data well; consider a different model or features.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
