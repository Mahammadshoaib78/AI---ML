{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: Classfication<br>\n",
    "\n",
    "Task 1:<br>\n",
    "Objective: Identify if an email is spam or not spam.<br>\n",
    "Load the UCI Spambase Dataset.<br>\n",
    "Goal: Create a model that classifies emails into two categories: \"spam\" and \"not spam.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9196525515743756\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       531\n",
      "           1       0.93      0.87      0.90       390\n",
      "\n",
      "    accuracy                           0.92       921\n",
      "   macro avg       0.92      0.91      0.92       921\n",
      "weighted avg       0.92      0.92      0.92       921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load UCI Spambase Dataset from UCI repository (direct link)\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "\n",
    "# According to the dataset description, there are 57 attributes and the last column is the label\n",
    "# Column names from UCI repository: https://archive.ics.uci.edu/ml/datasets/spambase\n",
    "column_names = [\n",
    "    'word_freq_make', 'word_freq_address', 'word_freq_all', 'word_freq_3d',\n",
    "    'word_freq_our', 'word_freq_over', 'word_freq_remove', 'word_freq_internet',\n",
    "    'word_freq_order', 'word_freq_mail', 'word_freq_receive', 'word_freq_will',\n",
    "    'word_freq_people', 'word_freq_report', 'word_freq_addresses', 'word_freq_free',\n",
    "    'word_freq_business', 'word_freq_email', 'word_freq_you', 'word_freq_credit',\n",
    "    'word_freq_your', 'word_freq_font', 'word_freq_000', 'word_freq_money',\n",
    "    'word_freq_hp', 'word_freq_hpl', 'word_freq_george', 'word_freq_650',\n",
    "    'word_freq_lab', 'word_freq_labs', 'word_freq_telnet', 'word_freq_857',\n",
    "    'word_freq_data', 'word_freq_415', 'word_freq_85', 'word_freq_technology',\n",
    "    'word_freq_1999', 'word_freq_parts', 'word_freq_pm', 'word_freq_direct',\n",
    "    'word_freq_cs', 'word_freq_meeting', 'word_freq_original', 'word_freq_project',\n",
    "    'word_freq_re', 'word_freq_edu', 'word_freq_table', 'word_freq_conference',\n",
    "    'char_freq_;', 'char_freq_(', 'char_freq_[', 'char_freq_!', 'char_freq_$',\n",
    "    'char_freq_#', 'capital_run_length_average', 'capital_run_length_longest',\n",
    "    'capital_run_length_total',\n",
    "    'spam'  # label column\n",
    "]\n",
    "\n",
    "# Load data into pandas dataframe\n",
    "df = pd.read_csv(url, header=None, names=column_names)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('spam', axis=1)\n",
    "y = df['spam']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features for better logistic regression performance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2:<br>\n",
    "Objective: Diagnose whether a tumor is malignant or benign.<br>\n",
    "Load the Breast Cancer Wisconsin dataset.<br>\n",
    "Goal: Build a binary classification model to classify tumors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9736842105263158\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "   malignant       0.98      0.95      0.96        43\n",
      "      benign       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load Breast Cancer Wisconsin dataset\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target  # 0 = malignant, 1 = benign\n",
    "\n",
    "# Split data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling for better model performance\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize and train logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=data.target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Task 3:<br>\n",
    "Objective: Determine whether a transaction is fraudulent or legitimate.<br>\n",
    "Use a credit card transaction dataset.<br>\n",
    "Goal: Classify transactions into \"fraudulent\" and \"legitimate\" categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[196   0]\n",
      " [  0   4]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       196\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00       200\n",
      "   macro avg       1.00      1.00      1.00       200\n",
      "weighted avg       1.00      1.00      1.00       200\n",
      "\n",
      "ROC-AUC Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Generate synthetic dataset (imbalanced)\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "X_legit = np.random.normal(0, 1, (980, 10))\n",
    "X_fraud = np.random.normal(2, 1, (20, 10))\n",
    "\n",
    "X = np.vstack((X_legit, X_fraud))\n",
    "y = np.array([0]*980 + [1]*20)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train logistic regression with balanced class weights\n",
    "model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_prob = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_prob))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
